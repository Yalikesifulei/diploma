% !TEX root = ../main.tex
% Розглянемо ймовірнісний розподіл на групі перестановок $\Sym{n}$, 
% заданий у такий спосіб:
% \begin{equation}\label{ESF}
%     \mathbb{P}(\{\pi\}) = \frac{
%         \theta^{\cycle(\pi)}
%     }{
%         \theta (\theta + 1) \dots (\theta + n - 1)
%     }, \; \pi \in \Sym{n},
% \end{equation}
% де $\theta > 0$ --- фіксований параметр, а $\cycle(\pi)$ позначає кількість циклів у $\pi$.
% Цей розподіл також відомий як
% \emph{міра Юенса} \cite{Manstavicius}. Тут і далі
% відповідні випадкові перестановки називатимемо
% \emph{перестановками Юенса} і, за потреби, для позначення
% такої перестановки $\sigma$ на $\Sym{n}$ застосовуватимемо
% позначення $\sigma \sim \ESF{n, \theta}$.

% \begin{remark}
%     Якщо $\theta = 1$, то формула \eqref{ESF} задає рівномірний розподіл,
%     тобто $\mathbb{P}(\{\pi\}) = \frac{1}{n!}$ для всіх $\pi \in \Sym{n}$.
% \end{remark}

% Перед тим, як вводити подальші поняття, розглянемо і доведемо наступну лему:

Як вже було згадано, для нерухомих точок перестановки $\sigma$ з рівномірним
розподілом на $\Sym{n}$ (він же $\ESF{1, \theta}$) кількість нерухомих точок 
при $n\to\infty$ збігається до $\Poiss{1}$. 

У \cite{last_penrose_2017} на ст. 8 пропонується довести, що у випадку рівномірного розподілу перестановки
розподіл нерухомих точок серед перших $\ceil*{\gamma n}$ натуральних чисел, де
$\gamma \in [0, 1]$, збігається до $\Poiss{\gamma}$.
Виявляється, що ця задача узагальнюється на випадок перестановок
з розподілом Юенса \eqref{ESF}. Розглянемо та доведемо відповідну лему.

\begin{lemma}\label{main_lemma}
    Нехай $\sigma$ --- випадкова перестановка на множині
    $\left\{1, \dots, n\right\}$, що задана розподілом \eqref{ESF},
    тобто, $\sigma$ є перестановкою Юенса з $\Sym{n}$.
    Нехай $\gamma \in [0, 1]$, а
    $X_n = \card\left\{i\in \left\{1,\dots,\ceil*{\gamma n} \right\} : \sigma(i) = i\right\}$
    --- кількість нерухомих точок
    $\sigma$ серед перших $\ceil*{\g n}$ натуральних чисел.
    Тоді $X_n$ за розподілом збігається до $\Poiss{\gamma\theta}$, тобто
    \begin{gather}
        \lim_{n\to\infty} \P{X_n = k} = \frac{(\gamma\theta)^k}{k!}e^{-\gamma\theta}, \; k \in \N_0.
    \end{gather} 
\end{lemma}
\begin{proof}
    Отримаємо явну формулу для ймовірностей $\P{X_n = k}$, починаючи з випадку $k=0$.
    Нехай $F_i$ позначає множину перестановок, для яких $i$ є нерухомою точкою. Тоді
    \begin{gather*}
        \P{X_n = 0} = \mathbb{P}\left( F_1^C \cap F_2^C \cap \dots \cap F_{\ceil*{\g n}}^C\right) = 
        1 - \mathbb{P}\left( F_1 \cup F_2 \cup \dots \cup F_{\ceil*{\g n}}\right) = \\ =
        1 - 
            \sum_{i} \mathbb{P}\left(F_i\right) +
            \sum_{i<j} \mathbb{P}\left(F_i \cap F_j\right) - \dots
            + (-1)^{\ceil*{\g n}}\mathbb{P}\left(F_1 \cap F_2 \cap \dots \cap F_{\ceil*{\g n}} \right).
    \end{gather*}
    У цьому виразі $\ceil*{\g n}$ однакових доданків виду $\mathbb{P}\left(F_i\right)$,
    $C_{\ceil*{\g n}}^2$ однакових доданків виду $\mathbb{P}\left(F_i \cap F_j\right)$ і так далі.
    Це означає, що достатньо знайти вирази для цих ймовірностей лише для конкретних наборів індексів.
    Якщо 1 є нерухомою точкою перестановки $\pi$, то вона має містити <<тотожний>>
    цикл $(1)$, тобто $\pi = (1) \circ \tilde{\pi}$, де 
    $\tilde{\pi}$ є перестановкою на множині $\left\{2, \dots, n\right\}$.
    Аналогічно, якщо 1 і 2 є нерухомими точками $\pi$,
    то $\pi = (1) (2) \circ \tilde{\pi}$, де 
    $\tilde{\pi}$ вже є перестановкою на множині $\left\{3, \dots, n\right\}$.
    Отже,
    \begin{gather*}
        \P{1, 2, \dots, i \text{ є нерухомими точками }\sigma} = 
        \sum_{\pi = (1) (2) \dots (i) \circ \tilde{\pi} \in S_n}
        \mathbb{P}\left(\{\pi\}\right) = \\ =
        \sum_{\pi = (1) (2) \dots (i) \circ \tilde{\pi} \in S_n}
        \frac{
            \theta^{\cycle(\pi)}
        }{
            \theta (\theta + 1) \dots (\theta + n - 1)
        } = \left[\cycle(\pi) \geq i\right] = \\ =
        \frac{
            \theta^i
        }{
            \theta (\theta + 1) \dots (\theta + n - 1)
        } \sum_{\pi = (1) (2) \dots (i) \circ \tilde{\pi} \in S_n} \theta^{\cycle(\pi) - i} = \\ =
        \frac{
            \theta^i
        }{
            \theta (\theta + 1) \dots (\theta + n - 1)
        } \sum_{\tilde{\pi} \in S_{n-i}} \theta^{\cycle(\tilde{\pi})}.
    \end{gather*} 
    Остання сума є сумою ймовірностей розподілу Юенса \eqref{ESF} на $\Sym{n-i}$, 
    але без константи нормування, тому дорівнює
    $\theta (\theta + 1) \dots (\theta + n - i - 1)$, отже
    \begin{gather*}
        \P{1, 2, \dots, i \text{ є нерухомими точками }\sigma} = 
        \frac{\theta^i}{
            (\theta + n - i) \dots (\theta + n - 1)
        }.
    \end{gather*}
    З цього отримуємо
    \begin{gather*}
        \P{X_n = 0} = \sum_{i=0}^{\ceil*{\gamma n}}
        (-1)^i C_{\ceil*{\gamma n}}^i \frac{\theta^i}{
            (\theta + n - i) \dots (\theta + n - 1)
        }.
    \end{gather*}
    $\P{X_n = k}$ для $k>0$ можна отримати аналогічно:
    існує $C_{\ceil*{\gamma n}}^k$ способів
    вибрати $k$ натуральних чисел, які будуть нерухомими точками,
    а для інших $\ceil*{\gamma n} - k$ застосувати формулу, аналогічну до $\P{X_n = 0}$:
    \begin{gather*}
        \P{X_n = k} = C_{\ceil*{\gamma n}}^k \sum_{i=0}^{\ceil*{\gamma n}-k} (-1)^i C_{\ceil*{\gamma n}-k}^i \frac{\theta^{i+k}}{
            (\theta + n - i - k) \dots (\theta + n - 1)
        }.
    \end{gather*}
    Тепер доведемо $\lim_{n\to\infty} \P{X_n = k} = \frac{(\gamma\theta)^k}{k!}e^{-\gamma\theta}$ за
    допомогою теореми \ref{th:series_dct}.
    \begin{gather*}
        \P{X_n = k} = \\ =
        \frac{
            (\ceil*{\g n})!
        }{
            k! (\ceil*{\g n} - k)!
        }
        \sum_{i=0}^{\ceil*{\gamma n}-k} (-1)^i
        \frac{
            (\ceil*{\g n} - k)!
        }{
            i! (\ceil*{\g n} - k - i)!
        } \frac{\theta^{i+k}}{
            (\theta + n - i - k) \dots (\theta + n - 1)
        } = \\ =
        \frac{\theta^k}{k!}
        \sum_{i=0}^{\ceil*{\gamma n}-k} 
        \underbrace{(-1)^i \frac{\theta^i}{i!} \frac{
            (\ceil*{\g n} - k - i + 1) \dots (\ceil*{\g n} - 1) \ceil*{\g n}
        }{
            (\theta + n - i - k) \dots (\theta + n - 2)(\theta + n - 1)
        }}_{f_n(i)} = \\ = 
        \frac{\theta^k}{k!}
        \sum_{i=0}^{\ceil*{\gamma n}-k} f_n(i) =
        \frac{\theta^k}{k!} \sum_{i=0}^{\infty} f_n(i) \mathds{1}\left\{i \leq \ceil*{\gamma n}-k\right\} =
        \frac{\theta^k}{k!} \sum_{i=0}^{\infty} \tilde{f}_n(i).
    \end{gather*}
    Знайдемо поточкову границю $\tilde{f}_n(i)$ при $n \to \infty$:
    \begin{gather*}
        \lim_{n\to\infty} \tilde{f}_n(i) = (-1)^i \frac{\theta^i}{i!} \cdot
        \lim_{n\to\infty} \frac{
            (\ceil*{\g n} - k - i + 1) \dots \ceil*{\g n}
        }{
            (\theta + n - i - k) \dots (\theta + n - 1)
        } \cdot \underbrace{\lim_{n\to\infty} \mathds{1}\left\{i \leq \ceil*{\gamma n}-k\right\}}_{= 1}.
    \end{gather*}
    Оскільки $\gamma n \leq \ceil*{\gamma n} \leq \gamma n + 1$, то 
    $
    \lim_{n\to\infty} \frac{
        (\ceil*{\g n} - k - i + 1) \dots \ceil*{\g n}
    }{
        (\theta + n - i - k) \dots (\theta + n - 1)
    } = \gamma^{i + k}
    $. Отже, 
    \begin{gather*}
        \lim_{n\to\infty} \tilde{f}_n(i) = (-1)^i \frac{\theta^i}{i!} \cdot \gamma^{i + k} = f(i).
    \end{gather*}
    Знайдемо тепер функцію $g$, для якої $|\tilde{f}_n(i)| \leq g(i)$ для всіх $i$ та $n$
    і $\sum_{i=0}^{\infty} g(i) < \infty$.
    Оскільки 
    $
    \lim_{n\to\infty} \frac{
        (\ceil*{\g n} - k - i + 1) \dots \ceil*{\g n}
    }{
        (\theta + n - i - k) \dots (\theta + n - 1)
    } = \gamma^{i + k} \leq \gamma^k$, то 
    ця послідовність з якогось номеру $n$ обмежена константою $C$, що не залежить від $i$, тому
    з цього ж номера
    \begin{gather*}
        |\tilde{f}_n(i)| \leq \frac{\theta^i}{i!} \cdot C = g(i).
    \end{gather*}
    Оскільки $\sum_{i=0}^{\infty} g(i) = C \cdot \sum_{i=0} \frac{\theta^i}{i!} = C \cdot e^{\theta} < \infty$,
    то $g$ є шуканою функцією.

    Отже, 
    \begin{gather*}
        \lim_{n\to\infty} \P{X_n = k} = \frac{\theta^k}{k!} \lim_{n\to\infty} \sum_{i=0}^{\infty} \tilde{f}_n(i) =
        \frac{\theta^k}{k!} \sum_{i=0}^{\infty} f(i) = \\ = \frac{\theta^k}{k!} \sum_{i=0}^{\infty} (-1)^i \frac{\theta^i}{i!} \gamma^{i + k} = 
        \frac{(\gamma \theta)^k}{k!} e^{-\gamma \theta},
    \end{gather*}
    що і треба було довести.
\end{proof}
% Дослідимо окремо швидкість цієї збіжності для $\gamma = 1$. Розглянемо модуль різниці $\left|\P{X_n = k} - \P{X = k}\right|$,
% де $X \sim \Poiss{\theta}$:
% \begin{gather*}
%     \left|\P{X_n = k} - \P{X = k}\right| =
%     \frac{\theta^k}{k!} \left|\sum_{i=0}^{n-k} (-1)^i
%     \frac{\theta^i}{i!} \frac{
%         (n - k - i + 1) \dots n
%     }{
%         (\theta + n - i - k) \dots (\theta + n - 1)
%     } - e^{-\theta}\right|.
% \end{gather*}

Користуючись позначеннями з леми \ref{main_lemma}, визначимо для $n \in \N$ точкові процеси
$P_n$ на $(E, \mathcal{E}) = \left([0, 1], \mathcal{B}([0, 1])\right)$ за правилом
\begin{gather}\label{Pn_def}
    P_n(F) = \card \left\{ i \in \{1, ..., n\} : \sigma(i) = i \text { та } \frac{i}{n} \in F\right\}, \; F \in \mathcal{E}.
\end{gather}
Отже, $P_n$
є випадковою точковою мірою 
з атомами у нерухомих точках перестановки Юенса $\sigma$, нормованих $n$, 
тому результат леми можна записати як 
\begin{gather*}
    \lim_{n\to\infty} \P{P_n\left([0, \gamma] \right) = k} = \P{N\left([0, \gamma] \right) = k}, \; k\in\N_0.
\end{gather*}
Тут $N$ є точковим процесом Пуассона
з мірою інтенсивності $\theta \cdot \mathrm{Leb}$ on $[0, 1]$. 
Виявляється, що має місце узагальнення цієї збіжності:
\begin{theorem}\label{main_th}
    Послідовність точкових процесів $P_n$ грубо збігається за розподілом
    до точкового процесу Пуассона $N$
    з мірою інтенсивності $\Lambda = \theta \cdot \mathrm{Leb}$ на $[0, 1]$ 
    ($P_n \overset{vd}{\longrightarrow} N, n\to\infty$).
\end{theorem}

Теорема \ref{kallenberg_th} формулює критерій грубої збіжності
точкових процесів, скористаємось позначеннями з неї.
% \begin{theorem*}
%     Нехай $\left(\xi_n, n \geq 1\right)$ --- послідовність 
%     точкових процесів на вимірному просторі $\left(E, \mathcal{E}\right)$,
%     а точковий процес $\xi$ --- простий. Нехай також
%     $\mathcal{U} \subset \hat{\mathcal{E}}_\xi$ --- фіксоване
%     розсікаюче кільце, де $\hat{\mathcal{E}}_\xi$ позначає сім'ю
%     борелевих підмножин $E$, для яких $\E \xi (\partial B) = 0$,
%     а $\mathcal{I}\subset\mathcal{U}$ --- напівкільце. 
%     Тоді 
%     $\xi_n \overset{vd}{\longrightarrow} \xi$ тоді і тільки тоді, коли
%     \begin{enumerate}
%         \item $\underset{n\to\infty}{\lim}\;\P{\xi_n(U) = 0} = \P{\xi(U) = 0}$ для $U\in\mathcal{U}$;
%         \item $\underset{n\to\infty}{\limsup}\; \P{\xi_n(I) > 1} \leq \P{\xi(I) > 1}$ для $I \in \mathcal{I}$.
%     \end{enumerate}
% \end{theorem*}

Розглянемо сім'ю множин $\mathcal{X}$, що складається зі
скінченних диз'юнктних об'єд\-нань інтервалів $\left<a,b\right> \subset [0, 1]$.
% де $\left<a,b\right>$ позначає одне з $[a, b]$, $(a, b)$, $[a, b)$ чи $(a, b]$.
Для точкового процесу Пуассона $N$
з мірою інтенсивності $\Lambda = \theta \cdot \mathrm{Leb}$ на $[0, 1]$ 
(який є простим),
$\E N(\partial B) = \Lambda (\partial B)$, тому 
для всіх $B \subset \mathcal{X}$ $\E N(\partial B) = 0$, бо
$\partial B$ складається зі скінченного об'єднання окремих точок.
Це означає, що $\mathcal{X} \subset \hat{\mathcal{E}}_N $.
Також, $\mathcal{X}$ є кільцем і розсікаючим класом, оскільки всі необхідні
умови очевидно виконуються.
Отже, для доведення теореми \ref{main_th}, можна використати теорему
\ref{kallenberg_th}
для $\xi_n = P_n$, $\xi = N$ та
$\mathcal{U} = \mathcal{I} = \mathcal{X}$.

\begin{proof}[Доведення теореми \ref{main_th}]\label{main_proof}
    Нехай $\left<\gamma_1, \delta_1 \right>, ..., \left<\gamma_m, \delta_m \right>$ ,
    де $\gamma_1 < \delta_1 < \gamma_2 < ... < \gamma_m < \delta_m$, --- 
    набір інтервалів в $[0, 1]$, що попарно не перетинаються, 
    % $\floor*{a}$ позначає $\max\left\{k\in\Z : k \leq a\right\}$,
    $I_j = \left<\gamma_j, \delta_j\right>$ і $I = \bigcup_{j=1}^m I_j \in \mathcal{X}$.
    Позначимо $Y_n = P_n (I)$, де $P_n(I)$ визначено формулою \eqref{Pn_def}.
    % Як у і лемі \ref{main_lemma},
    % позначимо $F_i$ множину перестановок, для яких $i$ є нерухомою точкою, тоді
    % \begin{gather*}
    %     \P{Y_n = 0} = 1 -
    %     \mathbb{P}\left(\bigcup_{i \in I} F_i \right)
    % \end{gather*}
    Нехай $M_n = \card \left\{ 
        i \in \{1, ..., n\} : \frac{i}{n} \in I
    \right\}$ і тоді, аналогічно лемі \ref{main_lemma},
    \begin{gather*}
        \P{Y_n = k} = C_{M_n}^k \sum_{i=0}^{M_n-k}(-1)^{i} C_{M_n-k}^{i} \frac{\theta^{i+k}}{
            (\theta + n - i - k) \dots (\theta + n - 1)
        }.
    \end{gather*}
    Оскільки 
    $\card \left\{ 
        i \in \{1, ..., n\} : \frac{i}{n} \in I_j
    \right\} = \ceil*{\delta_j n} - \floor*{\gamma_j n}$ (
        $\ceil*{\cdot}$ може змінюватися на $\floor*{\cdot}$ і навпаки
        в залежності від $n$ та включення кінцевих точок до інтервалу), а $\floor*{x} \leq x \leq \ceil*{x}$, то
    $\lim_{n\to\infty}\frac{M_n}{n} = \sum_{j=1}^m (\delta_j - \gamma_j)$,
    повторенням доведення збіжності у лемі \ref{main_lemma},
    отримуємо
    \begin{gather*}
            \lim_{n\to\infty}\P{Y_n = k} = 
            \frac{1}{k!} \left(
                \theta \sum_{j=1}^m (\delta_j - \gamma_j)
            \right)^k
            \exp\left\{ 
                -\theta \sum_{j=1}^m (\delta_j - \gamma_j)
            \right\}, k \in \N_0.
    \end{gather*}
    Оскільки $\Lambda(I) = \theta \cdot \mathrm{Leb}(I) = \theta \sum_{j=1}^m (\delta_j - \gamma_j)$,
    то
    \begin{gather*}
        \lim_{n\to\infty}\P{P_n(I) = 0} = \P{N(I) = 0}, I\in\mathcal{X}.
    \end{gather*}
    Так як $\P{P_n(I) > 1} = 1 - \left(
        \P{P_n(I) = 0} + \P{P_n(I) = 1}
    \right)$ і $\P{P_n(I) = 1} \to \P{N(I) = 1}$ для $I\in\mathcal{X}$,
    отримуємо 
    \begin{gather*}
        \lim_{n\to\infty}\P{P_n(I) > 1} = \P{N(I) > 1}, I\in\mathcal{X}.
    \end{gather*}

    Отже, обидві умови теореми \ref{kallenberg_th} справджуються, що і доводить
    $P_n \overset{vd}{\longrightarrow} N$ при $n\to\infty$.
\end{proof}

Варто також зауважити важливий наслідок теореми \ref{main_th}.

\vspace{10pt}
\noindent
\textbf{Наслідок \ref{main_th}.}
\textit{Оскільки граничний процес Пуассона $N$ простий і $N\left(\{0\}\right) = 0$ з ймовірністю 1, то в силу теореми
\ref{th:Skorohod_conv} має місце збіжність $P_n \overset{Sd}{\longrightarrow} N$.}
\vspace{10pt}

% \begin{corollary*}[\ref{main_th}]
%     Оскільки граничний процес Пуассона $N$ простий і $N\left(\{0\}\right) = 0$ з ймовірністю 1, то в силу теореми
%     \eqref{th:Skorohod_conv} має місце збіжність $P_n \overset{Sd}{\longrightarrow} N$.
% \end{corollary*}
Для наступних досліджень будуть важливі перестановки з принаймні однією нерухомою точкою.
З теореми \ref{main_th} для $\gamma = 1$ виконується $\P{X_n = 0} \to e^{-\theta}, n \to \infty$. 
Введемо ще один точковий процес $\widehat{P}_n$, що визначений для борелевих множин $F \in \mathcal{B}([0, 1])$ як 
\begin{gather}
    \P{\widehat{P}_n (F) = k} = \P{P_n(F) = k \mid P_n([0, 1]) > 0} = \begin{cases}
        \frac{\P{P_n(F) = k}}{1 - \P{P_n([0, 1]) = 0}}, & k > 0; \\
        \frac{\P{P_n(F) = 0, P_n(F^C) > 0}}{1 - \P{P_n([0, 1]) = 0}}, & k = 0.
    \end{cases} 
\end{gather}
В силу теореми \ref{th:point_proc_uniqueness_simple} достатньо визначити лише одновимірні розподіли.
Повторенням доведення \ref{main_th} можна отримати наступний результат:
\begin{theorem}\label{cond_th}
    Точковий процес $\widehat{P}_n$ грубо збігається за розподілом до точкового процесу $\widehat{N}$ на $[0, 1]$, 
    для якого
    \begin{gather}\label{Pn_cond_def}
        \P{\widehat{N} (F) = k} =
        \begin{cases}
            \frac{(\Lambda(F))^k}{k!} \cdot \frac{e^{-\Lambda(F)}}{1 - e^{-\theta}}, & k > 0 \\
            \frac{\P{N(F) = 0, N(F^C) > 0}}{1 - e^{-\theta}}, & k = 0.
        \end{cases}
    \end{gather}
    для всіх $F \in \mathcal{B}([0, 1])$ та $k \in \N$.
\end{theorem}
За властивістю 2 у означенні \ref{def:poiss_proc} маємо
\begin{gather*}
    \P{N(F) = 0, N(F^C) > 0} = \P{N(F) = 0}\cdot \P{N(F^C) > 0} = \\ =
    \P{N(F) = 0} \cdot \left(1 - \P{N(F^C) = 0}\right) = 
    e^{-\Lambda(F)} \cdot \left(1 - e^{-\Lambda(F^C)}\right) = \\ =
    e^{-\Lambda(F)} \cdot \left(1 - e^{-\theta} e^{\Lambda(F)}\right) = 
    e^{-\Lambda(F)} - e^{-\theta},
\end{gather*}
тому можна записати
\begin{gather}
    \P{\widehat{N} (F) = k} =
    \begin{cases}
        \frac{(\Lambda(F))^k}{k!} \cdot \frac{e^{-\Lambda(F)}}{1 - e^{-\theta}}, & k > 0 \\
        \frac{e^{-\Lambda(F)} - e^{-\theta}}{1 - e^{-\theta}}, & k = 0.
    \end{cases}
\end{gather}
Зокрема, для $F = [0, 1]$:
\begin{gather}
    \P{\widehat{N} ([0, 1]) = k} = 
    \begin{cases}
        \frac{\theta^k}{k!} \cdot \frac{e^{-\theta}}{1 - e^{-\theta}}, & k > 0 \\
        0, & k = 0.
    \end{cases}
\end{gather}

% Точковий процес $\widehat{N}$ можна назвати обумовленим процесом Пуассона, бо
% \begin{gather*}
%     \P{N(F) = k \mid N(F) > 0} = \frac{\P{N(F) = k, N(F) > 0}}{\P{N(F) > 0}} =
%     \begin{cases}
%         \frac{\P{N(F) = k}}{1 - \exp\left\{-\Lambda(F)\right\}}, & k > 0 \\
%         0, & k = 0
%     \end{cases}
% \end{gather*}
% тому $\P{N(F) = k \mid N(F) > 0} = \P{\widehat{N}(F) = k}$ для $k \in \N$.